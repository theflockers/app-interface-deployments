---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: pulp-push-disk-images
  labels:
    app.kubernetes.io/version: "0.2.0"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
    Tekton task to push disk images with pulp
  params:
    - name: snapshot_json
      type: string
      description: String containing a JSON representation of the snapshot spec
    - name: concurrentLimit
      type: string
      description: The maximum number of images to be pulled at once
      default: 3
    - name: exodusGwSecret
      type: string
      description: Env specific secret containing the Exodus Gateway configs
    - name: exodusGwEnv
      type: string
      description: Environment to use in the Exodus Gateway. Options are [live, pre]
    - name: pulpSecret
      type: string
      description: Env specific secret containing the rhsm-pulp credentials
    - name: udcacheSecret
      type: string
      description: Env specific secret containing the udcache credentials
    - name: cgwHostname
      type: string
      description: Env specific hostname for content gateway
    - name: cgwSecret
      type: string
      description: Env specific secret containing the content gateway credentials
    - name: productName
      type: string
      description: product name
    - name: productCode
      type: string
      description: product code
    - name: productVersionName
      type: string
      description: product version name
    - name: component_json
      type: string
      description: String containing a JSON representation of the components listed in the data.mapping in RPA
  results:
    - name: result
      description: Success if the task succeeds, the error otherwise
  steps:
    - name: pull-and-push-images
      image: quay.io/konflux-ci/release-service-utils:cff1fd1e9d8fabc256ff17f6731b2c037a0a1102
      env:
        - name: EXODUS_CERT
          valueFrom:
            secretKeyRef:
              name: $(params.exodusGwSecret)
              key: cert
        - name: EXODUS_KEY
          valueFrom:
            secretKeyRef:
              name: $(params.exodusGwSecret)
              key: key
        - name: EXODUS_URL
          valueFrom:
            secretKeyRef:
              name: $(params.exodusGwSecret)
              key: url
        - name: PULP_URL
          valueFrom:
            secretKeyRef:
              name: $(params.pulpSecret)
              key: pulp_url
        - name: PULP_CERT
          valueFrom:
            secretKeyRef:
              name: $(params.pulpSecret)
              key: konflux-release-rhsm-pulp.crt
        - name: PULP_KEY
          valueFrom:
            secretKeyRef:
              name: $(params.pulpSecret)
              key: konflux-release-rhsm-pulp.key
        - name: UDC_URL
          valueFrom:
            secretKeyRef:
              name: $(params.udcacheSecret)
              key: url
        - name: UDC_CERT
          valueFrom:
            secretKeyRef:
              name: $(params.udcacheSecret)
              key: cert
        - name: UDC_KEY
          valueFrom:
            secretKeyRef:
              name: $(params.udcacheSecret)
              key: key
        - name: DOCKER_CONFIG_JSON
          valueFrom:
            secretKeyRef:
              name: redhat-workloads-token
              key: .dockerconfigjson
        - name: "SNAPSHOT_JSON"
          value: "$(params.snapshot_json)"
        - name: CGW_USERNAME
          valueFrom:
            secretKeyRef:
              name: $(params.cgwSecret)
              key: username
        - name: CGW_TOKEN
          valueFrom:
            secretKeyRef:
              name: $(params.cgwSecret)
              key: token
      script: |
        #!/usr/bin/env bash
        set -ex

        STDERR_FILE=/tmp/stderr.txt

        exitfunc() {
            local err=$1
            local line=$2
            local command="$3"
            if [ "$err" -eq 0 ] ; then
                echo -n "Success" > "$(results.result.path)"
            else
                echo "$0: ERROR '$command' failed at line $line - exited with status $err" \
                  > "$(results.result.path)"
                if [ -f "$STDERR_FILE" ] ; then
                    cat "$STDERR_FILE" | tail -n 20 >> "$(results.result.path)"
                fi
            fi
            exit 0 # exit the script cleanly as there is no point in proceeding past an error or exit call
        }
        # due to set -e, this catches all EXIT and ERR calls and the task should never fail with nonzero exit code
        trap 'exitfunc $? $LINENO "$BASH_COMMAND"' EXIT

        # Setup required variables
        export EXODUS_GW_CERT=/tmp/exodus.crt
        export EXODUS_GW_KEY=/tmp/exodus.key
        export PULP_CERT_FILE=/tmp/pulp.crt
        export PULP_KEY_FILE=/tmp/pulp.key
        export UDCACHE_CERT=/tmp/udc.crt
        export UDCACHE_KEY=/tmp/udc.key
        EXODUS_GW_ENV=$(params.exodusGwEnv)
        export EXODUS_GW_ENV
        export EXODUS_GW_URL="$EXODUS_URL"
        export EXODUS_PULP_HOOK_ENABLED=True
        export EXODUS_GW_TIMEOUT=7200
        mkdir -p ~/.docker

        set +x
        echo "$EXODUS_CERT" > "$EXODUS_GW_CERT"
        echo "$EXODUS_KEY" > "$EXODUS_GW_KEY"
        echo "$PULP_CERT" > "$PULP_CERT_FILE"
        echo "$PULP_KEY" > "$PULP_KEY_FILE"
        echo "$UDC_CERT" > "$UDCACHE_CERT"
        echo "$UDC_KEY" > "$UDCACHE_KEY"
        # Quotes are added to the secret so it applies in k8s nicely. But now we have to remove them
        echo "$DOCKER_CONFIG_JSON" | sed -r 's/(^|\})[^{}]+(\{|$)/\1\2/g' > ~/.docker/config.json
        set -x

        export DISK_IMAGE_DIR="$(mktemp -d)"

        process_component() { # Expected argument is [component json]
            COMPONENT=$1
            PULLSPEC=$(jq -er '.containerImage' <<< "${COMPONENT}")
            DESTINATION="${DISK_IMAGE_DIR}/$(jq -er '.staged.destination' <<< "${COMPONENT}")/FILES" \
              || (echo Missing staged.destination value for component. This should be an existing pulp repo. Failing \
              && exit 1)
            mkdir -p "${DESTINATION}"
            DOWNLOAD_DIR=$(mktemp -d)
            cd "$DOWNLOAD_DIR"
            # oras has very limited support for selecting the right auth entry,
            # so create a custom auth file with just one entry
            AUTH_FILE=$(mktemp)
            select-oci-auth "${PULLSPEC}" > "$AUTH_FILE"
            oras pull --registry-config "$AUTH_FILE" "$PULLSPEC"
            NUM_MAPPED_FILES=$(jq '.staged.files | length' <<< "${COMPONENT}")
            for ((i = 0; i < NUM_MAPPED_FILES; i++)) ; do
                FILE=$(jq -c --arg i "$i" '.staged.files[$i|tonumber]' <<< "$COMPONENT")
                SOURCE=$(jq -er '.source' <<< "$FILE")
                FILENAME=$(jq -er '.filename' <<< "$FILE")
                # The .qcow2 images are not zipped
                if [ -f "${SOURCE}.gz" ] ; then
                    gzip -d "${SOURCE}.gz"
                fi
                DESTINATION_FILE="${DESTINATION}/${FILENAME}"
                # Albeit a rare one, this is a race condition since this is run in parallel.
                # The race condition is if two files have the same $DESTINATION_FILE and both
                # if checks are run before either mv is run a few lines below.
                if [ -f "${DESTINATION_FILE}" ] ; then
                    echo -n "Multiple files use the same destination value: $DESTINATION" >&2
                    echo " and filename value: $FILENAME. Failing..." >&2
                    exit 1
                fi
                mv "$SOURCE" "${DESTINATION_FILE}" || echo "didn't find mapped file: ${SOURCE}"
            done
        }

        RUNNING_JOBS="\j" # Bash parameter for number of jobs currently running
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")
        # Process each component in parallel
        for ((i = 0; i < NUM_COMPONENTS; i++)) ; do
            COMPONENT=$(jq -c --arg i "$i" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
            # Limit batch size to concurrent limit
            while (( ${RUNNING_JOBS@P} >= $(params.concurrentLimit) )); do
                wait -n
            done
            process_component "$COMPONENT" 2> "$STDERR_FILE" &
        done

        # Wait for remaining processes to finish
        while (( ${RUNNING_JOBS@P} > 0 )); do
            wait -n
        done

        # Change to the subdir with the images
        cd "${DISK_IMAGE_DIR}"

        STAGED_JSON='{"header":{"version": "0.2"},"payload":{"files":[]}}'

        # Add the files to the payload
        while IFS= read -r -d '' file ; do
            STAGED_JSON=$(jq --arg filename "$(basename "$file")" --arg path "$file" \
              '.payload.files[.payload.files | length] = 
              {"filename": $filename, "relative_path": $path}' <<< "$STAGED_JSON")
        done < <(find * -type f -print0)

        echo "$STAGED_JSON" | yq -P -I 4 > staged.yaml

        pulp_push_wrapper --debug --source "${DISK_IMAGE_DIR}" --pulp-url "$PULP_URL" \
          --pulp-cert $PULP_CERT_FILE --pulp-key $PULP_KEY_FILE --udcache-url "$UDC_URL" \
          2> "$STDERR_FILE"

        echo "Publishing to Developer Portal..."

        python3 <<EOF
        """
        Run push-cgw-metadata command to push metadata to CGW:
        1. Extract all components under contentGateway key from dataPath
        2. Find all the files in contentDir that starts with the component name
        4. Generate necessary metadata for each file
        5. Dump the metadata to a YAML file
        6. Run push-cgw-metadata to push the metadata
        """
        import os
        import json
        import yaml
        import hashlib
        import subprocess

        WORKSPACE_DIR = os.path.dirname("/tmp")
        METADATA_FILE_PATH = f"{WORKSPACE_DIR}/cgw_metadata.yaml"
        RESULT_FILE_JSON_PATH=f"{WORKSPACE_DIR}/results.json"

        os.makedirs(WORKSPACE_DIR, exist_ok=True)

        productName = "$(params.productName)"
        productCode = "$(params.productCode)"
        productVersionName = "$(params.productVersionName)"
        components = json.loads("$(params.component_json)")

        CONTENT_DIR= os.environ.get('DISK_IMAGE_DIR')
        content_list = os.listdir(CONTENT_DIR)

        # Default values for each component,
        # values from DATA_FILE takes presedence over these
        default_values_per_component = {
            'type': "FILE",
            'shortURL': f"/cgw/{productCode}",
            "hidden": False,
            "invisible": False
        }

        def generate_download_url(file_name):
            """
            Generate a download URL in this format:
            /content/origin/files/sha256/{checksum[:2]}{checksum}/{file_name}
            """
            prefix = "/content/origin/files/sha256"
            sha256_hash = hashlib.sha256()
            with open(CONTENT_DIR + "/" + file_name, "rb") as f:
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            checksum = sha256_hash.hexdigest()
            return f"{prefix}/{checksum[:2]}/{checksum}/{file_name}"

        def generate_metadata(content_list, components):
            """
            Generate metadata for each file in
            content_list that starts with the component name
            """
            metadata = []
            for file in content_list:
                matching_component = [
                    data
                    for data in components
                    if file.startswith(data['name'])]

                if matching_component:
                    print("Processing file: ", file)
                    for data in matching_component:
                        component = data.copy()
                        component.update({
                            'productName': productName,
                            'productCode': productCode,
                            'productVersionName': productVersionName,
                            'downloadURL': generate_download_url(file),
                            'label': file,
                        })
                        del component['name']
                        default_values_per_component['shortURL'] += f"/{file}"
                        metadata.append({
                            'type': 'file',
                            'action': 'create',
                            'metadata': {**default_values_per_component, **component}
                        })
                else:
                    print(f"Skipping file: {file} as it does not start with any component name")

            return metadata

        metadata = generate_metadata(content_list, components)
        print(len(metadata), "Files will be published to CGW")

        with open(METADATA_FILE_PATH, 'w') as file:
            yaml.dump(metadata, file, default_flow_style=False, sort_keys=False)

        print(f"YAML content dumped to {METADATA_FILE_PATH}")
        command = [
            'push-cgw-metadata',
            '--CGW_hostname', '$(params.cgwHostname)',
            '--CGW_username', '${CGW_USERNAME}',
            '--CGW_password', '${CGW_TOKEN}',
            '--CGW_filepath', METADATA_FILE_PATH
        ]

        try:
            result = subprocess.run(command, capture_output=True, text=True)
            command_output = result.stderr # using stderr to capture logged output
            print(f"Command succeeded with {command_output}")
        except subprocess.CalledProcessError as error:
            print(f"Command failed with return code {error.returncode}")
            command_output = error.stderr

        result_data = {"no_of_files_processed": len(metadata),
                      "metadata_file_path": METADATA_FILE_PATH,
                      "command_output": command_output}

        print(f"results: {results_data}")
        EOF
